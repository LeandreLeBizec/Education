{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic use of scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pre-formated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# load the IRIS dataset\n",
    "from sklearn.datasets import load_iris\n",
    "irisData=load_iris()\n",
    "# get info on the dataset\n",
    "#print(irisData.data)\n",
    "print(irisData.target)\n",
    "print(irisData.target_names)\n",
    "print(irisData.feature_names)\n",
    "#print(irisData.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** What type of machine learning problem is that?\n",
    "\n",
    "Your answer: On est dans le cas d'un apprentissage supervisé, car on connait les différentes classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** How many features are there? What kind of features?\n",
    "\n",
    "Il y a 4 attributs numériques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting parts of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt # replace the name \"pyplot\" by \"plt\" \n",
    "X=irisData.data\n",
    "y=irisData.target\n",
    "xi=0\n",
    "yi=1\n",
    "\n",
    "colors=[\"red\",\"green\",\"blue\"] # associate a color to each class label\n",
    "for num_label in range(3): # for each label\n",
    "        plt.scatter(X[y==num_label][:, xi],X[y==num_label][:,yi],color=colors[num_label],label=irisData.target_names[num_label])\n",
    "plt.legend()\n",
    "plt.xlabel(irisData.feature_names[xi]) \n",
    "plt.ylabel(irisData.feature_names[yi])\n",
    "plt.title(\"Iris Data - size of the sepals only\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** From the previous visualisation, what can you predict about the difficulty of this dataset?\n",
    "\n",
    "On voit que la classe setosa est bien séparée des deux autres classes, mais il est difficile de distinguer la classe versicolor de la classe virginica en considérant seulement ces deux attributs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on X is 0.9866666666666667\n",
      "class predicted is [0]\n",
      "proba of each class is [[1. 0. 0.]]\n",
      "misclassified training examples are: [[6.  2.7 5.1 1.6]\n",
      " [4.9 2.5 4.5 1.7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "nb_neighb = 15\n",
    "clf = neighbors.KNeighborsClassifier(nb_neighb) # to know more about the parameters, type help(neighbors.KNeighborsClassifier)\n",
    "\n",
    "\n",
    "clf.fit(X, y) # training\n",
    "print('accuracy on X is',clf.score(X,y))\n",
    "\n",
    "# to predict on a specific example\n",
    "print('class predicted is',clf.predict([[ 5.4, 3.2, 1.6, 0.4]]))\n",
    "print('proba of each class is',clf.predict_proba([[ 5.4, 3.2, 1.6, 0.4]]))\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "print('misclassified training examples are:',X[y_pred!=y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** What kind of problem do you see with the evaluation?\n",
    "\n",
    "On évalue ici le classifieur avec l'ensemble qui a servi à l'entrainer, et non un ensemble d'évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we want a test set and a training set, we can split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[0:100], y[0:100] # 100 examples for training\n",
    "X_test, y_test = X[100:], y[100:] # rest for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Explain why it is a really bad idea to split this iris dataset as we've done.\n",
    "\n",
    "Les données sont triées selon leur classe. On risque en séparant les données ainsi de ne pas bénéficier d'exemples de certaines classes pour construire le classifieur, et on aurait un ensemble d'évaluation ne contenant que des exemples appartenant à une seule classe. Il faudrait d'abord mélanger les données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is a much better way to split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train / test =  105 45\n",
      "nb of training data with class 0/1/2 = 36 34 35\n",
      "Confusion matrix\n",
      " [[14  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 15]]\n",
      "0.044444444444444446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import random # to generate random numbers\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed()) # if needed: help(train_test_split)\n",
    "print('size of train / test = ',len(X_train), len(X_test))\n",
    "print('nb of training data with class 0/1/2 =', len(X_train[y_train==0]) ,len(X_train[y_train==1]), len(X_train[y_train==2]))\n",
    "\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_pred =clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n',cm)\n",
    "\n",
    "print(2/(12+16+15+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:** What is on the diagonal of the confusion matrix?\n",
    "\n",
    "Il s'agit des objets bien classés. \n",
    "\n",
    "**Q7:** What is the real error rate (give details)?\n",
    "\n",
    "L'erreur réelle est nombre d'exemples mal classés sur le nombre d'objets. Ici $err=\\frac{2}{12+16+15+2}=0.0444=4.44\\%$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can prefer cross-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_folds = 10\n",
    "kf=KFold(n_splits=nb_folds,shuffle=True)\n",
    "score=0\n",
    "for training_ind,test_ind in kf.split(X):\n",
    "    #print(\"training index: \",training_ind,\"\\ntest index:\",test_ind,'\\n') \n",
    "    X_train=X[training_ind]\n",
    "    y_train=y[training_ind]\n",
    "    clf.fit(X_train, y_train)\n",
    "    X_test=X[test_ind]\n",
    "    y_test=y[test_ind]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = score + accuracy_score(y_pred,y_test)\n",
    "print('average accuracy:',score/nb_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or as a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "t_scores = cross_val_score(clf, X, y, cv=10)\n",
    "print(t_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use another dataset (a CSV file). Pandas helps us to read this type of file.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = 'heart.csv'\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "\n",
    "features = X.columns\n",
    "classes = ['Not heart disease','heart disease']\n",
    "\n",
    "print (features)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Source\n\u001b[1;32m      4\u001b[0m X_train,X_val,y_train,y_val\u001b[38;5;241m=\u001b[39mtrain_test_split(X,y,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m clf \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=20,criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "graph = Source(tree.export_graphviz(clf, out_file=None,\n",
    "                                    feature_names=features,\n",
    "                                    class_names=classes,\n",
    "                                    filled=True, rounded=True))\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Graphviz is not working with your setup, look at http://people.irisa.fr/Vincent.Claveau/cours/fd/TP1.html\n",
    "\n",
    "**Q8:** Explain each line displayed in the nodes/leaves of the tree.\n",
    "\n",
    "La première ligne représente le sélecteur, la deuxième correspond au calcul d'entropie associé à ce sélecteur. La 3ème ligne correspond au nombre d'exemples présents dans le noeud. Dans values, on a à gauche les exemples classés dans no_heart_disease, et à gauche ceux de la classe heart_disease. Enfin, class représente la classe majoritaire dans le noeud. \n",
    "    \n",
    "**Q9:** What is the name of this decision tree according to the course?\n",
    " \n",
    " C'est un Tmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another nice viz of the decision tree. (The dtreeviz package is available in github. It can be installed with 'pip install dtreeviz'. It requires graphviz to be installed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "graph = dtreeviz(clf, X_train, y_train,\n",
    "                target_name=\"target\",\n",
    "                feature_names=features,\n",
    "                class_names=classes\n",
    "                )\n",
    "\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10:** Explain what are the histograms displayed.\n",
    "\n",
    "Il s'agit des différentes valeurs prises pour les individus présents dans le noeud, pour le sélecteur correspondant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11** From the sklearn manual, explain what effect max_depth or min_samples_split will have on the decision tree. If time permits, show the effects experimentally.\n",
    "\n",
    "max_depth permet de contrôler la hauteur de l'arbre, et min_samples le nombre d'exemples nécessaires pour séparer un noeud. On évite ainsi le sur-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Tmax\n",
    "\n",
    "(from https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html)\n",
    "\n",
    "Here, we use a critrion called \"Cost Complexity\". Cost complexity pruning is all about finding the right parameter for alpha.We will get the alpha values for this tree and will check the accuracy with the pruned trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print(ccp_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each alpha we will append our model to a list\n",
    "t_clf = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    t_clf.append(clf)\n",
    "    \n",
    "# we remove the last element in clfs and ccp_alphas, because it is the trivial tree with only one node.\n",
    "t_clf = t_clf[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "node_counts = [clf.tree_.node_count for clf in t_clf]\n",
    "depth = [clf.tree_.max_depth for clf in t_clf]\n",
    "plt.scatter(ccp_alphas,node_counts)\n",
    "plt.scatter(ccp_alphas,depth)\n",
    "plt.plot(ccp_alphas,node_counts,label='no of nodes',drawstyle=\"steps-post\")\n",
    "plt.plot(ccp_alphas,depth,label='depth',drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.title('Tree complexity vs alpha')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# accuracy versus alpha\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for c in t_clf:\n",
    "    y_train_pred = c.predict(X_train)\n",
    "    y_val_pred = c.predict(X_val)\n",
    "    train_acc.append(accuracy_score(y_train_pred,y_train))\n",
    "    val_acc.append(accuracy_score(y_val_pred,y_val))\n",
    "\n",
    "plt.scatter(ccp_alphas,train_acc)\n",
    "plt.scatter(ccp_alphas,val_acc)\n",
    "plt.plot(ccp_alphas,train_acc,label='train_accuracy',drawstyle=\"steps-post\")\n",
    "plt.plot(ccp_alphas,val_acc,label='val_accuracy',drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12:** from the graph above, what is the best value for alpha. Replace it in the first line below.\n",
    "\n",
    "La meilleure valeur pour alpha est 0.02, puisque c'est celle qui permet de minimiser l'erreur réelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = 0.02 # <-- replace this value\n",
    "clf_ = tree.DecisionTreeClassifier(random_state=0,ccp_alpha=best_alpha)\n",
    "clf_.fit(X_train,y_train)\n",
    "y_train_pred = clf_.predict(X_train)\n",
    "y_val_pred = clf_.predict(X_val)\n",
    "\n",
    "print('Train score', accuracy_score(y_train_pred,y_train))\n",
    "print(confusion_matrix(y_train_pred,y_train))\n",
    "\n",
    "print('Validation score', accuracy_score(y_val_pred,y_val))\n",
    "print(confusion_matrix(y_val_pred,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn implements several variants of Bayesian learning, based on different assumptions about the data https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = 'weather.nominal.csv'\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "data2 = 'weather.csv'\n",
    "df2 = pd.read_csv(data2)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13:** Let us consider the weather_nominal dataset. What is the type of each feature?\n",
    "\n",
    "outlook, temperature, et humidity sont des attributs symboliques et windy est un attribut booléen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['play'])\n",
    "y_train = df['play']\n",
    "\n",
    "features = X_train.columns\n",
    "classes = ['no play','play']\n",
    "\n",
    "# we must convert the nominal features into integers\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "X_train = enc.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "clf = CategoricalNB().fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print('Train score',accuracy_score(y_train_pred,y_train))\n",
    "print(confusion_matrix(y_train_pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14:** Explain what is displayed by the two following code lines and link that wth what you've seen dutring the course. Do these figures corresponds to what you get when doing it by yourself (explain)?\n",
    "\n",
    "class_log_prior correspond au log de la probabilité à priori <br>\n",
    "feature_log_prob_ correspond au log de la probabilité à posteriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.class_log_prior_)\n",
    "print(clf.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15:** Let's consider the weather.csv dataset now. Explain what is the difference with the previous one.\n",
    "\n",
    "weather.csv a des attributs numériques au lieu d'attributs symboliques.\n",
    "\n",
    "\n",
    "**Q16:** Compute 'by hand' the a posteriori proba of each class for the following data sample P(play=0|x=\\['sunny',73,81,'TRUE'\\]) and  P(play=1|x=\\['sunny',73,81,'TRUE'\\]) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [ ['sunny',73,81,'TRUE'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = df2.drop(columns=['play'])\n",
    "\n",
    "print(X_train_num)\n",
    "print(y_train)\n",
    "\n",
    "Nbw0=0 #Nombre d'éléments de la classe 0\n",
    "Nbw1=0 #Nombre d'éléments de la classe 1\n",
    "for i in y_train:\n",
    "    if i==0:\n",
    "        Nbw0+=1\n",
    "    else:\n",
    "        Nbw1+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait l'hypothèse que les classes sont équiprobables, donc P(w=0)=P(w=1)=1/2\n",
    "\n",
    "Pour calculer les probabilités a priori, on se place sous l'hypothèse naïve. On considère donc que les attributs sont indépendants. \n",
    "\n",
    "On a donc P(x|w=0)=P(outlook='sunny'|w=0) * P(temperature=73|w=0) * P(humidity=81|w=0) * P(windy='True'|w=0)\n",
    "\n",
    "De même pour P(x|w=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(outlook='sunny'|w=0) et P(outlook='sunny'|w=1)\n",
    "POutlook0=0\n",
    "POutlook1=0\n",
    "for i in range(len(X_train_num)):\n",
    "    if X_train_num['outlook'][i]=='sunny':\n",
    "        if y_train[i]==0:\n",
    "            POutlook0+=1\n",
    "        else:\n",
    "            POutlook1+=1\n",
    "            \n",
    "POutlook0=POutlook0/Nbw0\n",
    "POutlook1=POutlook1/Nbw1\n",
    "\n",
    "print(\"P(outlook='sunny'|play=0) : \"+str(POutlook0))\n",
    "print(\"P(outlook='sunny'|play=1) : \"+str(POutlook1))\n",
    "\n",
    "#P(windy='True'|w=0) et P(windy='True'|w=1)\n",
    "PWindy0=0\n",
    "PWindy1=0\n",
    "\n",
    "for i in range(len(X_train_num)):\n",
    "    if X_train_num['windy'][i]==True:\n",
    "        if y_train[i]==0:\n",
    "            PWindy0+=1\n",
    "        else:\n",
    "            PWindy1+=1\n",
    "            \n",
    "PWindy0=PWindy0/Nbw0\n",
    "PWindy1=PWindy1/Nbw1    \n",
    "\n",
    "print(\"P(windy='True'|play=0) : \"+str(PWindy0))\n",
    "print(\"P(windy='True'|play=1) : \"+str(PWindy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import math\n",
    "\n",
    "#P(temperature='73'|w=0) et P(temperature='73'|w=1)\n",
    "vals_temp0=[]\n",
    "vals_temp1=[]\n",
    "\n",
    "for i in range(len(X_train_num)):\n",
    "    if y_train[i]==0:\n",
    "        vals_temp0.append(X_train_num['temperature'][i])\n",
    "    else:\n",
    "        vals_temp1.append(X_train_num['temperature'][i])\n",
    "        \n",
    "sigma_temp0 = statistics.pstdev(vals_temp0)\n",
    "sigma_temp1 = statistics.pstdev(vals_temp1)\n",
    "mean_temp0 = statistics.mean(vals_temp0)\n",
    "mean_temp1 = statistics.mean(vals_temp1)\n",
    "\n",
    "\n",
    "PTemp0=(1/math.sqrt(2*math.pi*(sigma_temp0**2)))*math.exp(-(73-mean_temp0)**2/(2*sigma_temp0**2))\n",
    "PTemp1=(1/math.sqrt(2*math.pi*(sigma_temp1**2)))*math.exp(-(73-mean_temp1)**2/(2*sigma_temp1**2))\n",
    "\n",
    "print(\"P(temperature=73|play=0) : \"+str(PTemp0))\n",
    "print(\"P(temperature=73|play=1) : \"+str(PTemp1))\n",
    "\n",
    "#P(humidity='81'|w=0) et P(humidity='81'|w=1)\n",
    "vals_hum0=[]\n",
    "vals_hum1=[]\n",
    "\n",
    "for i in range(len(X_train_num)):\n",
    "    if y_train[i]==0:\n",
    "        vals_hum0.append(X_train_num['humidity'][i])\n",
    "    else:\n",
    "        vals_hum1.append(X_train_num['humidity'][i])\n",
    "        \n",
    "sigma_hum0 = statistics.pstdev(vals_hum0)\n",
    "sigma_hum1 = statistics.pstdev(vals_hum1)\n",
    "mean_hum0 = statistics.mean(vals_hum0)\n",
    "mean_hum1 = statistics.mean(vals_hum1)\n",
    "\n",
    "\n",
    "PHum0=(1/math.sqrt(2*math.pi*(sigma_hum0**2)))*math.exp(-(73-mean_hum0)**2/(2*sigma_hum0**2))\n",
    "PHum1=(1/math.sqrt(2*math.pi*(sigma_hum1**2)))*math.exp(-(73-mean_hum1)**2/(2*sigma_hum1**2))\n",
    "\n",
    "print(\"P(humidity=81|play=0) : \"+str(PHum0))\n",
    "print(\"P(humidity=81|play=1) : \"+str(PHum1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilité à posteriori : \n",
    "PPosteriori0 = POutlook0*PTemp0*PHum0*PWindy0\n",
    "PPosteriori1 = POutlook1*PTemp1*PHum1*PWindy1\n",
    "\n",
    "print(\"P(x=['sunny',73,81,'True']|play=0) : \"+str(PPosteriori0))\n",
    "print(\"P(x=['sunny',73,81,'True']|play=1) : \"+str(PPosteriori1))\n",
    "\n",
    "#Calcul de P(x)\n",
    "#P(x)=P(x|w=0)P(w=0)+P(x|w=1)P(w=1)\n",
    "\n",
    "Px=PPosteriori0*(1/2) + PPosteriori1*(1/2)\n",
    "\n",
    "\n",
    "#Calcul de P(play=0|x=['sunny',73,81,'TRUE'])  P(play=1|x=['sunny',73,81,'TRUE'])\n",
    "\n",
    "Proba0=((1/2)*PPosteriori0)/Px\n",
    "Proba1=((1/2)*PPosteriori1)/Px\n",
    "\n",
    "print(\"P(play=0|x=['sunny',73,81,'True']) : \"+str(Proba0))\n",
    "print(\"P(play=1|x=['sunny',73,81,'True']) : \"+str(Proba1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(play=0|x=['sunny',73,81,'True']) > P(play=1|x=['sunny',73,81,'True'])\n",
    "\n",
    "On considère donc que le point x appartient à la classe 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
